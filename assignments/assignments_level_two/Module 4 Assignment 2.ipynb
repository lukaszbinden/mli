{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://www.anotsorandomwalk.com/backpropagation-example-with-numbers-step-by-step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.2f}'.format # suppress scientifc notation for floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases to learn with their initial values\n",
    "w1 = 0.82\n",
    "w2 = 0.53\n",
    "w3 = 0.44\n",
    "w4 = 0.15\n",
    "w5 = 0.61\n",
    "w6 = 0.39\n",
    "w7 = 0.11\n",
    "w8 = 0.41\n",
    "w9 = 0.50\n",
    "w10 = 0.45\n",
    "w11 = 0.23\n",
    "w12 = 0.68\n",
    "w13 = 0.49\n",
    "w14 = 0.71\n",
    "w15 = 0.23\n",
    "w16 = 0.21\n",
    "w17 = 0.44\n",
    "w18 = 0.62\n",
    "b1 = 0.5\n",
    "b2 = 0.5\n",
    "orig_w1  = w1 \n",
    "orig_w2  = w2 \n",
    "orig_w3  = w3 \n",
    "orig_w4  = w4 \n",
    "orig_w5  = w5 \n",
    "orig_w6  = w6 \n",
    "orig_w7  = w7 \n",
    "orig_w8  = w8 \n",
    "orig_w9  = w9 \n",
    "orig_w10 = w10\n",
    "orig_w11 = w11\n",
    "orig_w12 = w12\n",
    "orig_w13 = w13\n",
    "orig_w14 = w14\n",
    "orig_w15 = w15\n",
    "orig_w16 = w16\n",
    "orig_w17 = w17\n",
    "orig_w18 = w18\n",
    "orig_b1  = b1 \n",
    "orig_b2  = b2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights():\n",
    "    global w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, w11, w12, w13, w14, w15, w16, w17, w18, b1, b2\n",
    "    w1  = orig_w1 \n",
    "    w2  = orig_w2 \n",
    "    w3  = orig_w3 \n",
    "    w4  = orig_w4 \n",
    "    w5  = orig_w5 \n",
    "    w6  = orig_w6 \n",
    "    w7  = orig_w7 \n",
    "    w8  = orig_w8 \n",
    "    w9  = orig_w9 \n",
    "    w10 = orig_w10\n",
    "    w11 = orig_w11\n",
    "    w12 = orig_w12\n",
    "    w13 = orig_w13\n",
    "    w14 = orig_w14\n",
    "    w15 = orig_w15\n",
    "    w16 = orig_w16\n",
    "    w17 = orig_w17\n",
    "    w18 = orig_w18\n",
    "    b1  = orig_b1 \n",
    "    b2  = orig_b2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return np.divide(1, (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target values of the sample the network is trained on:\n",
    "x1 = 2\n",
    "x2 = 5\n",
    "x3 = 1\n",
    "x4 = 4\n",
    "t1 = 0.05\n",
    "t2 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the error function (= mean squared error MSE)\n",
    "def error(olist, tlist):\n",
    "    return 0.5 * (np.square(olist[0] - tlist[0]) + np.square(olist[1] - tlist[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement our simple MLP neural network with one hidden layer\n",
    "def forward_propagation(x1, x2, x3, x4) -> Tuple[float, float, float, float, float]:\n",
    "    zh1 = w1 * x1 + w4 * x2 + w7 * x3 + w10 * x4 + b1\n",
    "    zh2 = w2 * x1 + w5 * x2 + w8 * x3 + w11 * x4 + b1\n",
    "    zh3 = w3 * x1 + w6 * x2 + w9 * x3 + w12 * x4 + b1\n",
    "    \n",
    "    h1 = sigmoid(zh1)\n",
    "    h2 = sigmoid(zh2)\n",
    "    h3 = sigmoid(zh3)\n",
    "    \n",
    "    zo1 = w13 * h1 + w15 * h2 + w17 * h3 + b2\n",
    "    zo2 = w14 * h1 + w16 * h2 + w18 * h3 + b2\n",
    "    \n",
    "    o1 = sigmoid(zo1)\n",
    "    o2 = sigmoid(zo2)\n",
    "    \n",
    "    return h1, h2, h3, o1, o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from 1 forward propagation:\n",
      "Values of hidden neurons h1-h3:\n",
      "\th1: 0.9918374288468401\th2: 0.9973748797433398\th3: 0.9985719267115775\n",
      "Predictions (output nodes o1-o2):\n",
      "\to1: 0.8395344467680094\to2: 0.8841947961679333\n",
      "Ground truth (target values t1-t2):\n",
      "\tt1: 0.05\tt2: 0.1\n",
      "Total error: 0.6191630604850664\n"
     ]
    }
   ],
   "source": [
    "# FORWARD PROPAGATION\n",
    "# make one iteratoin through the network and show the total error.\n",
    "h1, h2, h3, o1, o2 = forward_propagation(x1, x2, x3, x4)\n",
    "e_init = error([o1, o2], [t1, t2])\n",
    "print(\"Results from 1 forward propagation:\")\n",
    "print(\"Values of hidden neurons h1-h3:\")\n",
    "print(f\"\\th1: {h1}\\th2: {h2}\\th3: {h3}\")\n",
    "print(\"Predictions (output nodes o1-o2):\")\n",
    "print(f\"\\to1: {o1}\\to2: {o2}\")\n",
    "print(\"Ground truth (target values t1-t2):\")\n",
    "print(f\"\\tt1: {t1}\\tt2: {t2}\")\n",
    "print(f\"Total error: {e_init}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of simple version of BACKPROPAGATION algorithm\n",
    "def backpropagation(iterations:int, alpha:float):\n",
    "    global w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, w11, w12, w13, w14, w15, w16, w17, w18, b1, b2\n",
    "    # 1. perform forward operation\n",
    "    # NB: this is equivalent to stochastic gradient descent as we do \n",
    "    # the backprop for each sample (here only one sample though), our sample is:\n",
    "    # input: x1, x2, x3, x4; target: t1, t2\n",
    "    for iter in range(iterations):\n",
    "        # do forward propagation\n",
    "        h1, h2, h3, o1, o2 = forward_propagation(x1, x2, x3, x4)\n",
    "        \n",
    "        # calculate error\n",
    "        e = error([o1, o2], [t1, t2])\n",
    "        \n",
    "        # perform backpropagation:\n",
    "        # 1) calculate all gradients\n",
    "        dEdw18 = (o2 - t2) * o2 * (1 - o2) * h3\n",
    "        dEdw17 = (o1 - t1) * o1 * (1 - o1) * h3\n",
    "        \n",
    "        dEdw16 = (o2 - t2) * o2 * (1 - o2) * h2\n",
    "        dEdw15 = (o1 - t1) * o1 * (1 - o1) * h2\n",
    "        \n",
    "        dEdw14 = (o2 - t2) * o2 * (1 - o2) * h1\n",
    "        dEdw13 = (o1 - t1) * o1 * (1 - o1) * h1\n",
    "        \n",
    "        dEdb2 = (o1 - t1) * o1 * (1 - o1) + (o2 - t2) * o2 * (1 - o2)\n",
    "        \n",
    "        dEdh1 = (o1 - t1) * o1 * (1 - o1) * w13 + (o2 - t2) * o2 * (1 - o2) * w14\n",
    "        dEdh2 = (o1 - t1) * o1 * (1 - o1) * w15 + (o2 - t2) * o2 * (1 - o2) * w16\n",
    "        dEdh3 = (o1 - t1) * o1 * (1 - o1) * w17 + (o2 - t2) * o2 * (1 - o2) * w18\n",
    "        \n",
    "        dEdw12 = dEdh3 * h3 * (1 - h3) * x4\n",
    "        dEdw11 = dEdh2 * h2 * (1 - h2) * x4\n",
    "        dEdw10 = dEdh1 * h1 * (1 - h1) * x4\n",
    "        \n",
    "        dEdw9 = dEdh3 * h3 * (1 - h3) * x3\n",
    "        dEdw8 = dEdh2 * h2 * (1 - h2) * x3\n",
    "        dEdw7 = dEdh1 * h1 * (1 - h1) * x3\n",
    "        \n",
    "        dEdw6 = dEdh3 * h3 * (1 - h3) * x2\n",
    "        dEdw5 = dEdh2 * h2 * (1 - h2) * x2\n",
    "        dEdw4 = dEdh1 * h1 * (1 - h1) * x2\n",
    "        \n",
    "        dEdw3 = dEdh3 * h3 * (1 - h3) * x1\n",
    "        dEdw2 = dEdh2 * h2 * (1 - h2) * x1\n",
    "        dEdw1 = dEdh1 * h1 * (1 - h1) * x1\n",
    "\n",
    "        dEdb1 = dEdh1 * h1 * (1 - h1) + dEdh2 * h2  * (1 - h2) + dEdh3 * h3 * (1 - h3)\n",
    "        \n",
    "        \n",
    "        # 2) update all weights and biases\n",
    "        # update weights w18 - w13 and b2\n",
    "        w18 = w18 - alpha * dEdw18\n",
    "        w17 = w17 - alpha * dEdw17\n",
    "        w16 = w16 - alpha * dEdw16\n",
    "        w15 = w15 - alpha * dEdw15\n",
    "        w14 = w14 - alpha * dEdw14\n",
    "        w13 = w13 - alpha * dEdw13\n",
    "        b2 = b2 - alpha * dEdb2\n",
    "        \n",
    "        # update weights w12 - w1 and b1\n",
    "        w12 = w12 - alpha * dEdw12\n",
    "        w11 = w11 - alpha * dEdw11\n",
    "        w10 = w10 - alpha * dEdw10\n",
    "        w9 = w9 - alpha * dEdw9\n",
    "        w8 = w8 - alpha * dEdw8\n",
    "        w7 = w7 - alpha * dEdw7\n",
    "        w6 = w6 - alpha * dEdw6\n",
    "        w5 = w5 - alpha * dEdw5\n",
    "        w4 = w4 - alpha * dEdw4\n",
    "        w3 = w3 - alpha * dEdw3\n",
    "        w2 = w2 - alpha * dEdw2\n",
    "        w1 = w1 - alpha * dEdw1\n",
    "        b1 = b1 - alpha * dEdb1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from 1 forward propagation after 1 backpropagation with learning rate 0.1:\n",
      "Values of hidden neurons h1-h3:\n",
      "\th1: 0.9918035421086362\th2: 0.9973732803917448\th3: 0.9985708617651421\n",
      "Predictions (output nodes o1-o2):\n",
      "\to1: 0.8326373555439436\to2: 0.8797625528518905\n",
      "Ground truth (target values t1-t2):\n",
      "\tt1: 0.05\tt2: 0.1\n",
      "Total error: 0.61028 (vs. 0.61916 w/o bp)\n"
     ]
    }
   ],
   "source": [
    "# perform one backpropagation through the network for a learning rate of 0.1\n",
    "backpropagation(iterations=1, alpha=0.1)\n",
    "h1, h2, h3, o1, o2 = forward_propagation(x1, x2, x3, x4)\n",
    "e = error([o1, o2], [t1, t2])\n",
    "print(\"Results from 1 forward propagation after 1 backpropagation with learning rate 0.1:\")\n",
    "print(\"Values of hidden neurons h1-h3:\")\n",
    "print(f\"\\th1: {h1}\\th2: {h2}\\th3: {h3}\")\n",
    "print(\"Predictions (output nodes o1-o2):\")\n",
    "print(f\"\\to1: {o1}\\to2: {o2}\")\n",
    "print(\"Ground truth (target values t1-t2):\")\n",
    "print(f\"\\tt1: {t1}\\tt2: {t2}\")\n",
    "print(f\"Total error: {round(e, 5)} (vs. {round(e_init, 5)} w/o bp)\")\n",
    "reset_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(prefix=\"\"):\n",
    "    print(f\"{prefix}\\torig_w1  = {orig_w1}\\t   w1  = {w1}\")\n",
    "    print(f\"{prefix}\\torig_w2  = {orig_w2}\\t   w2  = {w2}\")\n",
    "    print(f\"{prefix}\\torig_w3  = {orig_w3}\\t   w3  = {w3}\")\n",
    "    print(f\"{prefix}\\torig_w4  = {orig_w4}\\t   w4  = {w4}\")\n",
    "    print(f\"{prefix}\\torig_w5  = {orig_w5}\\t   w5  = {w5}\")\n",
    "    print(f\"{prefix}\\torig_w6  = {orig_w6}\\t   w6  = {w6}\")\n",
    "    print(f\"{prefix}\\torig_w7  = {orig_w7}\\t   w7  = {w7}\")\n",
    "    print(f\"{prefix}\\torig_w8  = {orig_w8}\\t   w8  = {w8}\")\n",
    "    print(f\"{prefix}\\torig_w9  = {orig_w9}\\t   w9  = {w9}\")\n",
    "    print(f\"{prefix}\\torig_w10 = {orig_w10}\\t   w10 = {w10}\")\n",
    "    print(f\"{prefix}\\torig_w11 = {orig_w11}\\t   w11 = {w11}\")\n",
    "    print(f\"{prefix}\\torig_w12 = {orig_w12}\\t   w12 = {w12}\")\n",
    "    print(f\"{prefix}\\torig_w13 = {orig_w13}\\t   w13 = {w13}\")\n",
    "    print(f\"{prefix}\\torig_w14 = {orig_w14}\\t   w14 = {w14}\")\n",
    "    print(f\"{prefix}\\torig_w15 = {orig_w15}\\t   w15 = {w15}\")\n",
    "    print(f\"{prefix}\\torig_w16 = {orig_w16}\\t   w16 = {w16}\")\n",
    "    print(f\"{prefix}\\torig_w17 = {orig_w17}\\t   w17 = {w17}\")\n",
    "    print(f\"{prefix}\\torig_w18 = {orig_w18}\\t   w18 = {w18}\")\n",
    "    print(f\"{prefix}\\torig_b1  = {orig_b1}\\t   b1  = {b1}\")\n",
    "    print(f\"{prefix}\\torig_b2  = {orig_b2}\\t   b2  = {b2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network weights and biases after 1 backpropagation:\n",
      "\torig_w1  = 0.82\t   w1  = 0.82\n",
      "\torig_w2  = 0.53\t   w2  = 0.53\n",
      "\torig_w3  = 0.44\t   w3  = 0.44\n",
      "\torig_w4  = 0.15\t   w4  = 0.15\n",
      "\torig_w5  = 0.61\t   w5  = 0.61\n",
      "\torig_w6  = 0.39\t   w6  = 0.39\n",
      "\torig_w7  = 0.11\t   w7  = 0.11\n",
      "\torig_w8  = 0.41\t   w8  = 0.41\n",
      "\torig_w9  = 0.5\t   w9  = 0.5\n",
      "\torig_w10 = 0.45\t   w10 = 0.45\n",
      "\torig_w11 = 0.23\t   w11 = 0.23\n",
      "\torig_w12 = 0.68\t   w12 = 0.68\n",
      "\torig_w13 = 0.49\t   w13 = 0.49\n",
      "\torig_w14 = 0.71\t   w14 = 0.71\n",
      "\torig_w15 = 0.23\t   w15 = 0.23\n",
      "\torig_w16 = 0.21\t   w16 = 0.21\n",
      "\torig_w17 = 0.44\t   w17 = 0.44\n",
      "\torig_w18 = 0.62\t   w18 = 0.62\n",
      "\torig_b1  = 0.5\t   b1  = 0.5\n",
      "\torig_b2  = 0.5\t   b2  = 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Network weights and biases after 1 backpropagation:\")\n",
    "print_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with alpha=0.01 and #iterations=1...\n",
      "\t*** RESULTS of 0.01|1 ***\n",
      "\t\tPredictions.: \to1: 0.8388552153960736 [0.05] \to2: 0.8837580401824678 [0.1]\n",
      "\t\tError.......: \t0.6182846082041242308235950986272655427456\n",
      "\n",
      "\n",
      "training with alpha=0.01 and #iterations=1000...\n",
      "\t*** RESULTS of 0.01|1000 ***\n",
      "\t\tPredictions.: \to1: 0.16512952106233383 [0.05] \to2: 0.2089647453295036 [0.1]\n",
      "\t\tError.......: \t0.0125640611723829721119161106912542891223\n",
      "\n",
      "\n",
      "training with alpha=0.01 and #iterations=10000...\n",
      "\t*** RESULTS of 0.01|10000 ***\n",
      "\t\tPredictions.: \to1: 0.06124925544267304 [0.05] \to2: 0.09915188009823875 [0.1]\n",
      "\t\tError.......: \t0.0000636325276911362333479363351251834047\n",
      "\n",
      "\n",
      "training with alpha=0.01 and #iterations=100000...\n",
      "\t*** RESULTS of 0.01|100000 ***\n",
      "\t\tPredictions.: \to1: 0.05000481064537019 [0.05] \to2: 0.09999914206629129 [0.1]\n",
      "\t\tError.......: \t0.0000000000119391795631335950789155538234\n",
      "\t\tNetwork details:\n",
      "\t\th1: 0.9909285678018119\th2: 0.9974910611647885\th3: 0.998556598705048\n",
      "\t\torig_w1  = 0.82\t   w1  = 0.8154338050799086\n",
      "\t\torig_w2  = 0.53\t   w2  = 0.532036892227318\n",
      "\t\torig_w3  = 0.44\t   w3  = 0.4395988573411437\n",
      "\t\torig_w4  = 0.15\t   w4  = 0.13858451269975783\n",
      "\t\torig_w5  = 0.61\t   w5  = 0.6150922305682909\n",
      "\t\torig_w6  = 0.39\t   w6  = 0.3889971433528519\n",
      "\t\torig_w7  = 0.11\t   w7  = 0.10771690253995403\n",
      "\t\torig_w8  = 0.41\t   w8  = 0.41101844611365895\n",
      "\t\torig_w9  = 0.5\t   w9  = 0.4997994286705554\n",
      "\t\torig_w10 = 0.45\t   w10 = 0.4408676101598161\n",
      "\t\torig_w11 = 0.23\t   w11 = 0.23407378445463412\n",
      "\t\torig_w12 = 0.68\t   w12 = 0.6791977146822874\n",
      "\t\torig_w13 = 0.49\t   w13 = -0.4508925358052969\n",
      "\t\torig_w14 = 0.71\t   w14 = -0.1078186420377883\n",
      "\t\torig_w15 = 0.23\t   w15 = -0.717047991356428\n",
      "\t\torig_w16 = 0.21\t   w16 = -0.6131936055662476\n",
      "\t\torig_w17 = 0.44\t   w17 = -0.5081436011130764\n",
      "\t\torig_w18 = 0.62\t   w18 = -0.20415677275324892\n",
      "\t\torig_b1  = 0.5\t   b1  = 0.4985347773241792\n",
      "\t\torig_b2  = 0.5\t   b2  = -1.2748763045136666\n",
      "\n",
      "\n",
      "training with alpha=0.05 and #iterations=1...\n",
      "\t*** RESULTS of 0.05|1 ***\n",
      "\t\tPredictions.: \to1: 0.8361150582577266 [0.05] \to2: 0.8819966924600235 [0.1]\n",
      "\t\tError.......: \t0.6147478559189827329589661530917510390282\n",
      "\n",
      "\n",
      "training with alpha=0.05 and #iterations=1000...\n",
      "\t*** RESULTS of 0.05|1000 ***\n",
      "\t\tPredictions.: \to1: 0.07472379503872348 [0.05] \to2: 0.10633903051607196 [0.1]\n",
      "\t\tError.......: \t0.0003257246745002494907675338886576810182\n",
      "\n",
      "\n",
      "training with alpha=0.05 and #iterations=10000...\n",
      "\t*** RESULTS of 0.05|10000 ***\n",
      "\t\tPredictions.: \to1: 0.05029369935461014 [0.05] \to2: 0.0999468303732798 [0.1]\n",
      "\t\tError.......: \t0.0000000445431600519879129973661033899818\n",
      "\n",
      "\n",
      "training with alpha=0.05 and #iterations=100000...\n",
      "\t*** RESULTS of 0.05|100000 ***\n",
      "\t\tPredictions.: \to1: 0.05000000000001178 [0.05] \to2: 0.09999999999999848 [0.1]\n",
      "\t\tError.......: \t0.0000000000000000000000000000704940674566\n",
      "\t\tNetwork details:\n",
      "\t\th1: 0.9909200740131638\th2: 0.9974902807948683\th3: 0.9985563217184124\n",
      "\t\torig_w1  = 0.82\t   w1  = 0.8153940269303424\n",
      "\t\torig_w2  = 0.53\t   w2  = 0.5320246221850762\n",
      "\t\torig_w3  = 0.44\t   w3  = 0.43959178783283026\n",
      "\t\torig_w4  = 0.15\t   w4  = 0.13848506732603486\n",
      "\t\torig_w5  = 0.61\t   w5  = 0.6150615554628279\n",
      "\t\torig_w6  = 0.39\t   w6  = 0.38897946958214985\n",
      "\t\torig_w7  = 0.11\t   w7  = 0.1076970134651993\n",
      "\t\torig_w8  = 0.41\t   w8  = 0.41101231109253805\n",
      "\t\torig_w9  = 0.5\t   w9  = 0.49979589391639295\n",
      "\t\torig_w10 = 0.45\t   w10 = 0.4407880538607972\n",
      "\t\torig_w11 = 0.23\t   w11 = 0.2340492443703143\n",
      "\t\torig_w12 = 0.68\t   w12 = 0.6791835756656606\n",
      "\t\torig_w13 = 0.49\t   w13 = -0.4509195729073871\n",
      "\t\torig_w14 = 0.71\t   w14 = -0.10780771931230923\n",
      "\t\torig_w15 = 0.23\t   w15 = -0.7170769004407552\n",
      "\t\torig_w16 = 0.21\t   w16 = -0.6131843697921582\n",
      "\t\torig_w17 = 0.44\t   w17 = -0.5081730246349351\n",
      "\t\torig_w18 = 0.62\t   w18 = -0.20414792129461665\n",
      "\t\torig_b1  = 0.5\t   b1  = 0.4985052184741899\n",
      "\t\torig_b2  = 0.5\t   b2  = -1.2748970975586762\n",
      "\n",
      "\n",
      "training with alpha=1.0 and #iterations=1...\n",
      "\t*** RESULTS of 1.0|1 ***\n",
      "\t\tPredictions.: \to1: 0.7597794165147492 [0.05] \to2: 0.8329870093550347 [0.1]\n",
      "\t\tError.......: \t0.5205283879956277282019527774536982178688\n",
      "\n",
      "\n",
      "training with alpha=1.0 and #iterations=1000...\n",
      "\t*** RESULTS of 1.0|1000 ***\n",
      "\t\tPredictions.: \to1: 0.05000454383036606 [0.05] \to2: 0.09999918955757 [0.1]\n",
      "\t\tError.......: \t0.0000000000106516056639195897657798907995\n",
      "\n",
      "\n",
      "training with alpha=1.0 and #iterations=10000...\n",
      "\t*** RESULTS of 1.0|10000 ***\n",
      "\t\tPredictions.: \to1: 0.05000000000000058 [0.05] \to2: 0.09999999999999995 [0.1]\n",
      "\t\tError.......: \t0.0000000000000000000000000000001673873863\n",
      "\n",
      "\n",
      "training with alpha=1.0 and #iterations=100000...\n",
      "\t*** RESULTS of 1.0|100000 ***\n",
      "\t\tPredictions.: \to1: 0.05000000000000058 [0.05] \to2: 0.09999999999999995 [0.1]\n",
      "\t\tError.......: \t0.0000000000000000000000000000001673873863\n",
      "\t\tNetwork details:\n",
      "\t\th1: 0.9907084034845804\th2: 0.9974707775825421\th3: 0.9985494456129896\n",
      "\t\torig_w1  = 0.82\t   w1  = 0.8144145556808888\n",
      "\t\torig_w2  = 0.53\t   w2  = 0.5317189507642526\n",
      "\t\torig_w3  = 0.44\t   w3  = 0.4394166425136201\n",
      "\t\torig_w4  = 0.15\t   w4  = 0.1360363892022374\n",
      "\t\torig_w5  = 0.61\t   w5  = 0.6142973769106387\n",
      "\t\torig_w6  = 0.39\t   w6  = 0.3885416062840545\n",
      "\t\torig_w7  = 0.11\t   w7  = 0.10720727784044733\n",
      "\t\torig_w8  = 0.41\t   w8  = 0.41085947538212625\n",
      "\t\torig_w9  = 0.5\t   w9  = 0.4997083212568089\n",
      "\t\torig_w10 = 0.45\t   w10 = 0.4388291113617893\n",
      "\t\torig_w11 = 0.23\t   w11 = 0.23343790152851485\n",
      "\t\torig_w12 = 0.68\t   w12 = 0.6788332850272403\n",
      "\t\torig_w13 = 0.49\t   w13 = -0.4509180901755715\n",
      "\t\torig_w14 = 0.71\t   w14 = -0.10777878799761069\n",
      "\t\torig_w15 = 0.23\t   w15 = -0.7171028288554544\n",
      "\t\torig_w16 = 0.21\t   w16 = -0.6131865025587576\n",
      "\t\torig_w17 = 0.44\t   w17 = -0.5082098867252007\n",
      "\t\torig_w18 = 0.62\t   w18 = -0.20415893147620967\n",
      "\t\torig_b1  = 0.5\t   b1  = 0.4977750744793869\n",
      "\t\torig_b2  = 0.5\t   b2  = -1.2749488209966915\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train network for 1, 1000, 10000 and 100000 iterations for learning rates 0.01, 0.05 and 0.1\n",
    "# print error, o1 and o2 for\n",
    "learning_rates = [0.01, 0.05, 1.0]\n",
    "iterations = [1, 1000, 10000, 100000]\n",
    "print_details = iterations[-1]\n",
    "for lr in learning_rates:\n",
    "    for num_iter in iterations:\n",
    "        print(f\"training with alpha={lr} and #iterations={num_iter}...\")\n",
    "        backpropagation(iterations=num_iter, alpha=lr)\n",
    "        h1, h2, h3, o1, o2 = forward_propagation(x1, x2, x3, x4)\n",
    "        e = error([o1, o2], [t1, t2])\n",
    "        \n",
    "        print(f\"\\t*** RESULTS of {lr}|{num_iter} ***\")\n",
    "        print(f\"\\t\\tPredictions.: \\to1: {o1} [{t1}] \\to2: {o2} [{t2}]\")\n",
    "        print(f\"\\t\\tError.......: \\t{e:.40f}\")\n",
    "        if num_iter == print_details:\n",
    "            print(\"\\t\\tNetwork details:\")\n",
    "            print(f\"\\t\\th1: {h1}\\th2: {h2}\\th3: {h3}\")\n",
    "            print_weights(\"\\t\")\n",
    "        reset_weights()\n",
    "        print(\"\\n\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
